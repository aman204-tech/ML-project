{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe7d5a8-65dd-4d39-8b9a-95539bfe70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a601393f-78a2-4ae0-9d4e-83a7b784fd9e",
   "metadata": {},
   "source": [
    "# Region detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf698f2-9965-4259-8549-d1ab012651ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_mouth(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)\n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"No faces detected.\")\n",
    "        return image, None\n",
    "    \n",
    "    (x, y, w, h) = faces[0]\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    \n",
    "    mouth_roi_y_start = int(y + 0.6 * h)\n",
    "    mouth_roi = gray[mouth_roi_y_start: y + h, x: x + w]\n",
    "  \n",
    "    mouth_cascade = cv2.CascadeClassifier('haarcascade_mcs_mouth.xml')\n",
    "    mouths = mouth_cascade.detectMultiScale(mouth_roi, scaleFactor=1.1, minNeighbors=5)\n",
    "    \n",
    "    if len(mouths) == 0:\n",
    "        print(\"No mouth detected.\")\n",
    "        return image, None\n",
    "\n",
    "    best_candidate = None\n",
    "    best_y = -1\n",
    "    for (mx, my, mw, mh) in mouths:\n",
    "        absolute_y = mouth_roi_y_start + my \n",
    "        if absolute_y > best_y:\n",
    "            best_y = absolute_y\n",
    "            best_candidate = (mx, my, mw, mh)\n",
    "\n",
    "    if best_candidate is None:\n",
    "        print(\"No mouth detected.\")\n",
    "        return image, None\n",
    "\n",
    "    mx, my, mw, mh = best_candidate\n",
    "    mouth_x = x + mx\n",
    "    mouth_y = mouth_roi_y_start + my\n",
    "    cv2.rectangle(image, (mouth_x, mouth_y), (mouth_x + mw, mouth_y + mh), (0, 255, 0), 2)\n",
    "    detected_mouth = (mouth_x, mouth_y, mw, mh)\n",
    "\n",
    "    return image, detected_mouth\n",
    "\n",
    "video_capture = cv2.VideoCapture('test.mp4')\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "frame_width = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "output_video = cv2.VideoWriter('detected_mouth_output.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    output_frame, mouth_coords = detect_mouth(frame)\n",
    "    output_video.write(output_frame)\n",
    "\n",
    "# Clean up\n",
    "video_capture.release()\n",
    "output_video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
